#
# Copyright (c) 2021 salesforce.com, inc.
# All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause
#
"""
Base class/mixin for AutoML hyperparameter search.
"""
from abc import abstractmethod
from collections import Iterator
from copy import deepcopy
from typing import Tuple, Optional, Any

from merlion.models.base import LayeredModel, LayeredModelConfig
from merlion.models.forecast.base import ForecasterBase
from merlion.utils import TimeSeries
from merlion.utils.misc import AutodocABCMeta


class AutoMLMixIn(LayeredModel, metaclass=AutodocABCMeta):
    """
    Base Interface for Implemented AutoML Layers

    This abstract class contains all of the methods that Layers should implement. Ideally, these would be generated by
    an existing mix-in.
    """

    config_class = LayeredModelConfig

    def train(self, train_data: TimeSeries, **kwargs):
        original_train_data = train_data
        train_data = self.train_pre_process(train_data, require_even_sampling=False, require_univariate=False)

        candidate_thetas = self.generate_theta(train_data)
        # need to call evaluate_theta on original training data since evaluate_theta often trains another model
        # and therefore we might be applying transform twice
        theta, model, train_result = self.evaluate_theta(candidate_thetas, original_train_data, **kwargs)
        if model is not None:
            self.model = model
            return train_result
        else:
            model = deepcopy(self.model)
            model.reset()
            self.set_theta(model, theta, train_data)
            self.model = model
            return self.model.train(original_train_data, **kwargs)

    @abstractmethod
    def generate_theta(self, train_data: TimeSeries) -> Iterator:
        """
        :param train_data: Training data to use for generation of hyperparameters :math:`\theta`

        Returns an iterator of hyperparameter candidates for consideration with th underlying model.
        """
        raise NotImplementedError

    @abstractmethod
    def evaluate_theta(
        self, thetas: Iterator, train_data: TimeSeries, train_config=None
    ) -> Tuple[Any, Optional[ForecasterBase], Optional[Tuple[TimeSeries, Optional[TimeSeries]]]]:
        """
        :param thetas: Iterator of the hyperparameter candidates
        :param train_data: Training data
        :param train_config: Training configuration

        Return the optimal hyperparameter, as well as optionally a model and result of the training procedure.
        """
        raise NotImplementedError

    @abstractmethod
    def set_theta(self, model, theta, train_data: TimeSeries = None):
        """
        :param model: Underlying base model to which the new theta is applied
        :param theta: Hyperparameter to apply
        :param train_data: Training data (Optional)

        Sets the hyperparameter to the provided ``model``. This is used to apply the :math:`\theta` to the model, since
        this behavior is custom to every model. Oftentimes in internal implementations, ``model`` is the optimal model.
        """
        raise NotImplementedError
